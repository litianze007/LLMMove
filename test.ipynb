{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      category    place_id         place_name  comment_id  comment_user_id   \n",
      "0          CE7   756993733  íˆ¬ì¸í”Œë ˆì´ìŠ¤ ë””ì§€í„¸ë¯¸ë””ì–´ì‹œí‹°ì—­ì     10840268       2350725315  \\\n",
      "1          CE7   756993733  íˆ¬ì¸í”Œë ˆì´ìŠ¤ ë””ì§€í„¸ë¯¸ë””ì–´ì‹œí‹°ì—­ì     10517631       1650546034   \n",
      "2          CE7   756993733  íˆ¬ì¸í”Œë ˆì´ìŠ¤ ë””ì§€í„¸ë¯¸ë””ì–´ì‹œí‹°ì—­ì     10349082       3371210705   \n",
      "3          CE7   972496863      ë©”ê°€MGCì»¤í”¼ ìˆ˜ìƒ‰ìì´ì      9461669       1231775476   \n",
      "4          CE7   972496863      ë©”ê°€MGCì»¤í”¼ ìˆ˜ìƒ‰ìì´ì      9246847       1030013027   \n",
      "...        ...         ...                ...         ...              ...   \n",
      "16553      FD6    15528437             ê´‘í™”ë¬¸ìˆ˜ì œë¹„     7025846        891589374   \n",
      "16554      FD6  1195558165               ë¦¬ìš°í‚¤ì¹œ    10188764        418219292   \n",
      "16555      FD6  1195558165               ë¦¬ìš°í‚¤ì¹œ    10149964       2377789139   \n",
      "16556      FD6  1195558165               ë¦¬ìš°í‚¤ì¹œ     7963312       2234012693   \n",
      "16557      FD6  1594659846       ë§Œí‰ìš°ë™ ìƒì•”KGITì     11038430        418219292   \n",
      "\n",
      "                                         comment_content  comment_point   \n",
      "0                                                    NaN              2  \\\n",
      "1                                              ì ‘ê·¼ì´ í¸í•œ íˆ¬ì¸              5   \n",
      "2      ì‹œê°„ ë•Œìš°ë ¤ ë°©ë¬¸í–ˆëŠ”ë° ë„ˆë¬´ ë”ì›Œìš”.... 1ì¸µ ë¡œë¹„ë‘ ë¬¸ì—†ì´ ì—°ê²°ë˜ì–´ìˆë˜ë° ì§„ì§œ ...              3   \n",
      "3                                    ë§ˆê°ì‹œê°„ ë˜ì§€ë„ ì•Šì•—ëŠ”ë° ëˆˆì¹˜ì¤˜ìš”ã…œ              1   \n",
      "4                    ì•„ë©”ë¦¬ì¹´ë…¸ ë¨¹ì„ë•Œì€ ëª°ëëŠ”ë°, ì •ëŸ‰ì„ ì•ˆì§€í‚¤ê³  ì ê²Œì¤˜ìš”..ë¼ë–¼ë¥˜              1   \n",
      "...                                                  ...            ...   \n",
      "16553  ìš”ì¦˜ ë¬¼ê°€ì— ê°€ì„±ë¹„ ìµœê³ ğŸ‘ ë°”ì§€ë½ì´ ìˆì–´ì„œ êµ­ë¬¼ì´ ì‹œì›í•¨, ëŒ€ì‹  ë§Œë‘ê°€ ì‹œíŒì¸ ê²ƒ ...              4   \n",
      "16554                              ë§›ê³¼ ê°€ì„±ë¹„ë¥¼ ë‹¤ ì¡ì€ ìƒì•”ë™ ìµœê³ ë§›ì§‘              5   \n",
      "16555  ê°€ì„±ë¹„ ê°œ ë¯¸ì¹œ ìƒëŸ¬ë“œê°€ê²Œ ìƒì•”ì— ì˜¤ë˜ì˜¤ë˜ ìˆì–´ì£¼ì„¸ìš” ì œë°œì œë°œì œë°œ. ê°€ê²© ê°œí˜œì”ë° ...              5   \n",
      "16556                   ì„ ê²°ì œí•˜ê³  ì°¾ì•„ê°€ëŠ” ë§›ì§‘\\nìƒëŸ¬ë“œëŠ” ë§¤ìš° í›Œë¥­í•¨ :-)\\n              5   \n",
      "16557  ìš°ë™ì„¸íŠ¸ 8,700â‚©\\nì „ì²´ì ìœ¼ë¡œ ì–‘ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ë§›ë„ ê·¸ëƒ¥ ê·¸ë ‡ê³ ìš”. ë¬¸ì œëŠ”...              3   \n",
      "\n",
      "      comment_date        row_id  \n",
      "0      2024.08.22.   756993733_1  \n",
      "1      2024.07.09.   756993733_2  \n",
      "2      2024.06.14.   756993733_3  \n",
      "3      2024.02.02.   972496863_1  \n",
      "4      2024.01.01.   972496863_2  \n",
      "...            ...           ...  \n",
      "16553  2023.02.17.    15528437_3  \n",
      "16554  2024.08.06.  1195558165_1  \n",
      "16555  2024.05.18.  1195558165_2  \n",
      "16556  2023.06.28.  1195558165_3  \n",
      "16557  2024.09.19.  1594659846_1  \n",
      "\n",
      "[16558 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# å‡è®¾æ•°æ®å­˜å‚¨åœ¨ CSV æ–‡ä»¶ä¸­\n",
    "file_path = \"./datasets/mapogu-4k-ce7-fd6.csv\"  # æ›¿æ¢æˆä½ çš„æ–‡ä»¶è·¯å¾„\n",
    "\n",
    "# è¯»å– CSV æ–‡ä»¶\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥è®¡æ•°æ¯ä¸ª place_id çš„å‡ºç°æ¬¡æ•°\n",
    "place_id_counter = {}\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ä¸ºæ¯è¡Œç”Ÿæˆ row_id\n",
    "def generate_row_id(row):\n",
    "    place_id = row['place_id']\n",
    "    if place_id not in place_id_counter:\n",
    "        place_id_counter[place_id] = 1\n",
    "    else:\n",
    "        place_id_counter[place_id] += 1\n",
    "    return f\"{place_id}_{place_id_counter[place_id]}\"\n",
    "\n",
    "# åˆ›å»ºæ–°çš„ row_id åˆ—\n",
    "df['row_id'] = df.apply(generate_row_id, axis=1)\n",
    "\n",
    "\n",
    "# æ‰“å°ç”Ÿæˆçš„ DataFrame\n",
    "print(df)\n",
    "\n",
    "# ä¿å­˜å›CSVï¼ˆå¯é€‰ï¼‰\n",
    "df.to_csv(\"./datasets/mapogu-4k-ce7-fd6_row_id.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶ä¸­çš„è¡Œæ•°ä¸º: 16558\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# è®¾ç½®æ–‡ä»¶è·¯å¾„\n",
    "file_path = './datasets/mapogu-4k-ce7-fd6_row_id.csv'\n",
    "\n",
    "# è¯»å– CSV æ–‡ä»¶\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# è·å–è¡Œæ•°\n",
    "row_count = df.shape[0]\n",
    "\n",
    "\n",
    "# è¾“å‡ºè¡Œæ•°\n",
    "print(f\"æ–‡ä»¶ä¸­çš„è¡Œæ•°ä¸º: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶ä¿®å¤å®Œæˆï¼Œç»“æœå·²å†™å…¥ ./datasets/fixed_row_id_score.json\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–åŸå§‹æ–‡ä»¶ï¼Œå¹¶åœ¨å¼€å§‹å’Œç»“å°¾æ·»åŠ æ–¹æ‹¬å·\n",
    "input_file_path = './datasets/mapogu-4k-ce7-fd6_row_id_score.json'\n",
    "output_file_path = './datasets/fixed_row_id_score.json'\n",
    "\n",
    "try:\n",
    "    # è¯»å–åŸå§‹æ–‡ä»¶å¹¶é€è¡Œå†™å…¥ï¼Œç¡®ä¿åŠ å…¥æ•°ç»„ç»“æ„\n",
    "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        outfile.write('[')  # åœ¨æ–‡ä»¶å¼€å§‹æ·»åŠ å·¦æ–¹æ‹¬å·\n",
    "        \n",
    "        first_line = True  # æ ‡è®°æ˜¯å¦æ˜¯ç¬¬ä¸€è¡Œ\n",
    "        for line in infile:\n",
    "            if not first_line:\n",
    "                outfile.write(',\\n')  # åœ¨æ¯è¡Œä¹‹é—´æ·»åŠ é€—å·åˆ†éš”\n",
    "            outfile.write(line.strip())\n",
    "            first_line = False\n",
    "        \n",
    "        outfile.write(']')  # åœ¨æ–‡ä»¶ç»“å°¾æ·»åŠ å³æ–¹æ‹¬å·\n",
    "    \n",
    "    print(f\"æ–‡ä»¶ä¿®å¤å®Œæˆï¼Œç»“æœå·²å†™å…¥ {output_file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"æ–‡ä»¶å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åˆ é™¤ sentiment_score ä¸åœ¨ [-1, 1] èŒƒå›´å†…çš„è®°å½•ï¼Œå‰©ä½™ 13223 æ¡ã€‚\n",
      "ä¸ç¬¦åˆæ¡ä»¶çš„è®°å½•å·²ä¿å­˜ï¼Œæ•°é‡ä¸ºï¼š613\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    # è¯»å– JSON æ–‡ä»¶\n",
    "    with open('./datasets/fixed_row_id_score.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # ç­›é€‰å‡ºç¬¦åˆæ¡ä»¶å’Œä¸ç¬¦åˆæ¡ä»¶çš„è®°å½•\n",
    "    filtered_data = [item for item in data if -1 <= item['sentiment_score'] <= 1]\n",
    "    removed_data = [item for item in data if not (-1 <= item['sentiment_score'] <= 1)]\n",
    "    \n",
    "    # å°†ç­›é€‰åçš„æ•°æ®å†™å›æ–‡ä»¶ï¼ˆæˆ–ä¿å­˜ä¸ºæ–°æ–‡ä»¶ï¼‰\n",
    "    with open('./datasets/filtered_row_id_score.json', 'w') as file:\n",
    "        json.dump(filtered_data, file, indent=4)\n",
    "    \n",
    "    # å¦‚æœæƒ³ä¿ç•™è¢«åˆ é™¤çš„è®°å½•\n",
    "    if removed_data:\n",
    "        with open('./datasets/removed_row_id_score.json', 'w') as file:\n",
    "            json.dump(removed_data, file, indent=4)\n",
    "    \n",
    "    print(f\"å·²åˆ é™¤ sentiment_score ä¸åœ¨ [-1, 1] èŒƒå›´å†…çš„è®°å½•ï¼Œå‰©ä½™ {len(filtered_data)} æ¡ã€‚\")\n",
    "    if removed_data:\n",
    "        print(f\"ä¸ç¬¦åˆæ¡ä»¶çš„è®°å½•å·²ä¿å­˜ï¼Œæ•°é‡ä¸ºï¼š{len(removed_data)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"å‘ç”Ÿé”™è¯¯: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†å®Œæˆï¼Œæ›´æ–°åçš„CSVæ–‡ä»¶å·²ä¿å­˜åˆ° ./datasets/updated_mapogu-4k-ce7-fd6_row_id.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# æ–‡ä»¶è·¯å¾„\n",
    "json_file_path = './datasets/filtered_row_id_score.json'  # ä½ çš„JSONæ–‡ä»¶è·¯å¾„\n",
    "csv_file_path = './datasets/mapogu-4k-ce7-fd6_row_id.csv'  # ä½ çš„CSVæ–‡ä»¶è·¯å¾„\n",
    "output_csv_file_path = './datasets/updated_mapogu-4k-ce7-fd6_row_id.csv'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„\n",
    "\n",
    "# è¯»å–JSONæ–‡ä»¶\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥æ˜ å°„row_idåˆ°sentiment_score\n",
    "row_id_to_sentiment = {item['row_id']: item['sentiment_score'] for item in json_data}\n",
    "\n",
    "# è¯»å–CSVæ–‡ä»¶å¹¶é€è¡Œå¤„ç†\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as csv_file, open(output_csv_file_path, 'w', newline='', encoding='utf-8') as output_csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_writer = csv.writer(output_csv_file)\n",
    "    \n",
    "    # è·å–è¡¨å¤´\n",
    "    header = next(csv_reader)\n",
    "    # åœ¨è¡¨å¤´ä¸­å¢åŠ ä¸€ä¸ªsentiment_scoreåˆ—\n",
    "    header.append('sentiment_score')\n",
    "    csv_writer.writerow(header)\n",
    "    \n",
    "    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®\n",
    "    for row in csv_reader:\n",
    "        row_id = row[-1]  # å‡è®¾ row_id åœ¨CSVæ–‡ä»¶çš„æœ€åä¸€åˆ—\n",
    "        sentiment_score = row_id_to_sentiment.get(row_id, 'null')  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„row_idï¼Œsentiment_scoreä¸ºnull\n",
    "        row.append(sentiment_score)\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"å¤„ç†å®Œæˆï¼Œæ›´æ–°åçš„CSVæ–‡ä»¶å·²ä¿å­˜åˆ° {output_csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° ./datasets/final_mapogu-4k-ce7-fd6_row_id_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# æ–‡ä»¶è·¯å¾„\n",
    "csv_file_path = './datasets/updated_mapogu-4k-ce7-fd6_row_id.csv'  # ä½ çš„ç°æœ‰CSVæ–‡ä»¶è·¯å¾„\n",
    "output_csv_file_path = './datasets/final_mapogu-4k-ce7-fd6_row_id_scaled.csv'  # æœ€ç»ˆè¾“å‡ºçš„æ–‡ä»¶è·¯å¾„\n",
    "\n",
    "# å®šä¹‰ç¼©æ”¾åˆ° 0-5 åŒºé—´çš„å‡½æ•°\n",
    "def scale_to_range(value, min_value, max_value, new_min, new_max):\n",
    "    # å°† value ä» (min_value, max_value) åŒºé—´ç¼©æ”¾åˆ° (new_min, new_max) åŒºé—´\n",
    "    return ((value - min_value) / (max_value - min_value)) * (new_max - new_min) + new_min\n",
    "\n",
    "# è¯»å–CSVæ–‡ä»¶å¹¶é€è¡Œå¤„ç†\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as csv_file, open(output_csv_file_path, 'w', newline='', encoding='utf-8') as output_csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    fieldnames = csv_reader.fieldnames + ['sentiment_comment_point_sum']  # åœ¨è¡¨å¤´ä¸­å¢åŠ  sentiment_comment_point_sum åˆ—\n",
    "    csv_writer = csv.DictWriter(output_csv_file, fieldnames=fieldnames)\n",
    "    \n",
    "    # å†™å…¥è¡¨å¤´\n",
    "    csv_writer.writeheader()\n",
    "    \n",
    "    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®\n",
    "    for row in csv_reader:\n",
    "        comment_point = float(row['comment_point'])  # æŒ‰åå­—è·å– comment_point\n",
    "        sentiment_score = row['sentiment_score']  # æŒ‰åå­—è·å– sentiment_score\n",
    "\n",
    "        if sentiment_score == 'null':  # å¦‚æœ sentiment_score æ˜¯ 'null'\n",
    "            sentiment_comment_point_sum = comment_point\n",
    "        else:\n",
    "            sentiment_score = float(sentiment_score)\n",
    "            # è®¡ç®— sentiment_score å’Œ comment_point çš„å’Œ\n",
    "            total = sentiment_score + comment_point\n",
    "            \n",
    "            # å‡è®¾ sentiment_score åœ¨ [-1, 1]ï¼Œcomment_point åœ¨ [0, 5]\n",
    "            # total çš„å¯èƒ½èŒƒå›´æ˜¯ [-1, 6]ï¼Œæˆ‘ä»¬å°†å…¶ç¼©æ”¾åˆ° [0, 5] åŒºé—´\n",
    "            sentiment_comment_point_sum = scale_to_range(total, -1, 6, 0, 5)\n",
    "\n",
    "        # ä¿ç•™ä¸¤ä½å°æ•°\n",
    "        sentiment_comment_point_sum = round(sentiment_comment_point_sum, 2)\n",
    "\n",
    "        # åœ¨è¡Œä¸­æ·»åŠ  sentiment_comment_point_sum åˆ—\n",
    "        row['sentiment_comment_point_sum'] = sentiment_comment_point_sum\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {output_csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰€æœ‰è¡Œçš„ sentiment_comment_point_sum åˆ—éƒ½æœ‰å€¼ã€‚\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# æ–‡ä»¶è·¯å¾„\n",
    "csv_file_path = './datasets/final_mapogu-4k-ce7-fd6_row_id_scaled.csv'  # å·²ç»ç”Ÿæˆçš„CSVæ–‡ä»¶è·¯å¾„\n",
    "\n",
    "# è®¡æ•°å™¨æ¥è·Ÿè¸ªæ˜¯å¦æœ‰ç©ºå€¼\n",
    "empty_rows = []\n",
    "\n",
    "# è¯»å–CSVæ–‡ä»¶å¹¶é€è¡Œå¤„ç†\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    # é€è¡Œæ£€æŸ¥ sentiment_comment_point_sum åˆ—æ˜¯å¦ä¸ºç©º\n",
    "    for row_num, row in enumerate(csv_reader, start=1):\n",
    "        sentiment_comment_point_sum = row.get('sentiment_comment_point_sum', '').strip()\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼æˆ–ä¸º 'null'\n",
    "        if sentiment_comment_point_sum == '' or sentiment_comment_point_sum == 'null':\n",
    "            empty_rows.append(row_num)  # è®°å½•ç©ºç¼ºè¡Œçš„è¡Œå·\n",
    "\n",
    "# è¾“å‡ºç»“æœ\n",
    "if empty_rows:\n",
    "    print(f\"å‘ç° sentiment_comment_point_sum åˆ—å­˜åœ¨ç©ºç¼ºå€¼çš„è¡Œå·: {empty_rows}\")\n",
    "else:\n",
    "    print(\"æ‰€æœ‰è¡Œçš„ sentiment_comment_point_sum åˆ—éƒ½æœ‰å€¼ã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
